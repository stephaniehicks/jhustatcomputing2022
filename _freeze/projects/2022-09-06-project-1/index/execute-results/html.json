{
  "hash": "de7bb153f17bdcf2b03cce9332c4c441",
  "result": {
    "markdown": "---\ntitle: \"Project 1\"\nauthor: \n  - name: Stephanie Hicks\n    url: https://stephaniehicks.com\n    affiliation: Department of Biostatistics, Johns Hopkins\n    affiliation_url: https://publichealth.jhu.edu\ndescription: \"Finding great chocolate bars!\"\ndate: 2022-09-06\ndraft: true\ncategories: [project 1, projects]\n---\n\n\n# Background\n\n**Due date: Sept 16 at 11:59pm**\n\n### To submit your project\n\nPlease write up your project using R Markdown and `knitr`. Compile your document as an **HTML file** and submit your HTML file to the dropbox on Courseplus. Please **show all your code** for each of the answers to each part.\n\nTo get started, [watch this video on setting up your R Markdown document](https://www.stephaniehicks.com/jhustatcomputing2021/posts/2021-09-02-literate-programming/#create-and-knit-your-first-r-markdown-document).\n\n### Install `tidyverse`\n\nBefore attempting this assignment, you should first install the `tidyverse` package if you have not already. The `tidyverse` package is actually a collection of many packages that serves as a convenient way to install many packages without having to do them one by one. This can be done with the `install.packages()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tidyverse\")\n```\n:::\n\n\nRunning this function will install a host of other packages so it make take a minute or two depending on how fast your computer is. Once you have installed it, you will want to load the package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n### Data\n\nThat data for this part of the assignment comes from [TidyTuesday](https://www.tidytuesday.com), which is a weekly podcast and global [community activity](https://github.com/rfordatascience/tidytuesday) brought to you by the R4DS Online Learning Community. The goal of TidyTuesday is to help R learners learn in real-world contexts.\n\n![](https://github.com/rfordatascience/tidytuesday/raw/master/static/tt_logo.png){.preview-image}\n\n\\[**Source**: [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/static/tt_logo.png)\\]\n\nIf we look at the [TidyTuesday github repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022#2022-data) from 2022, we see this dataset chocolate bar reviews.\n\nTo access the data, you need to install the `tidytuesdayR` R package and use the function `tt_load()` with the date of '2022-01-18' to load the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tidytuesdayR\")\n```\n:::\n\n\nThis is how you can download the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuesdata <- tidytuesdayR::tt_load('2022-01-18')\nchocolate <- tuesdata$chocolate\n```\n:::\n\n\nHowever, if you use this code, you will hit an API limit after trying to compile the document a few times. Instead, I suggest you use the following code below. Here, I provide the code below for you to avoid re-downloading data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(tidyverse)\n\n# tests if a directory named \"data\" exists locally\nif(!dir.exists(here(\"data\"))) { dir.create(here(\"data\")) }\n\n# saves data only once (not each time you knit a R Markdown)\nif(!file.exists(here(\"data\",\"chocolate.RDS\"))) {\n  url_csv <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv'\n  chocolate <- readr::read_csv(url_csv)\n  \n  # save the file to RDS objects\n  saveRDS(chocolate, file= here(\"data\",\"chocolate.RDS\"))\n}\n```\n:::\n\n\nHere we read in the `.RDS` dataset locally from our computing environment:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchocolate <- readRDS(here(\"data\",\"chocolate.RDS\"))\nas_tibble(chocolate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,530 × 10\n     ref compan…¹ compa…² revie…³ count…⁴ speci…⁵ cocoa…⁶ ingre…⁷ most_…⁸ rating\n   <dbl> <chr>    <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>    <dbl>\n 1  2454 5150     U.S.A.     2019 Tanzan… Kokoa … 76%     3- B,S… rich c…   3.25\n 2  2458 5150     U.S.A.     2019 Domini… Zorzal… 76%     3- B,S… cocoa,…   3.5 \n 3  2454 5150     U.S.A.     2019 Madaga… Bejofo… 76%     3- B,S… cocoa,…   3.75\n 4  2542 5150     U.S.A.     2021 Fiji    Matasa… 68%     3- B,S… chewy,…   3   \n 5  2546 5150     U.S.A.     2021 Venezu… Sur de… 72%     3- B,S… fatty,…   3   \n 6  2546 5150     U.S.A.     2021 Uganda  Semuli… 80%     3- B,S… mildly…   3.25\n 7  2542 5150     U.S.A.     2021 India   Anamal… 68%     3- B,S… milk b…   3.5 \n 8   797 A. Morin France     2012 Bolivia Bolivia 70%     4- B,S… vegeta…   3.5 \n 9   797 A. Morin France     2012 Peru    Peru    63%     4- B,S… fruity…   3.75\n10  1011 A. Morin France     2013 Panama  Panama  70%     4- B,S… brief …   2.75\n# … with 2,520 more rows, and abbreviated variable names ¹​company_manufacturer,\n#   ²​company_location, ³​review_date, ⁴​country_of_bean_origin,\n#   ⁵​specific_bean_origin_or_bar_name, ⁶​cocoa_percent, ⁷​ingredients,\n#   ⁸​most_memorable_characteristics\n```\n:::\n:::\n\n\nWe can take a glimpse at the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(chocolate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 2,530\nColumns: 10\n$ ref                              <dbl> 2454, 2458, 2454, 2542, 2546, 2546, 2…\n$ company_manufacturer             <chr> \"5150\", \"5150\", \"5150\", \"5150\", \"5150…\n$ company_location                 <chr> \"U.S.A.\", \"U.S.A.\", \"U.S.A.\", \"U.S.A.…\n$ review_date                      <dbl> 2019, 2019, 2019, 2021, 2021, 2021, 2…\n$ country_of_bean_origin           <chr> \"Tanzania\", \"Dominican Republic\", \"Ma…\n$ specific_bean_origin_or_bar_name <chr> \"Kokoa Kamili, batch 1\", \"Zorzal, bat…\n$ cocoa_percent                    <chr> \"76%\", \"76%\", \"76%\", \"68%\", \"72%\", \"8…\n$ ingredients                      <chr> \"3- B,S,C\", \"3- B,S,C\", \"3- B,S,C\", \"…\n$ most_memorable_characteristics   <chr> \"rich cocoa, fatty, bready\", \"cocoa, …\n$ rating                           <dbl> 3.25, 3.50, 3.75, 3.00, 3.00, 3.25, 3…\n```\n:::\n:::\n\n\nHere is a data dictionary for what all the column names mean:\n\n-   <https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-01-18/readme.md#data-dictionary>\n\n# Part 1: Explore data\n\nIn this part, use functions from `dplyr` and `ggplot2` to answer the following questions.\n\n1.  Make a histogram of the `rating` scores to visualize the overall distribution of scores. Change the number of bins from the default to 10, 15, 20, and 25. Pick on the one that you think looks the best. Explain what the difference is when you change the number of bins and explain why you picked the one you did.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here and describe your answer afterwards\n```\n:::\n\n\nThe ratings are discrete values making the histogram look strange. When you make the bin size smaller, it aggregates the ratings together in larger groups removing that effect. I picked 15, but there really is no wrong answer. Just looking for an answer here.\n\n2.  Consider the countries where the beans originated from. How many reviews come from each country of bean origin?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n3.  What is average `rating` scores from reviews of chocolate bars that have Ecuador as `country_of_bean_origin` in this dataset? For this same set of reviews, also calculate (1) the total number of reviews and (2) the standard deviation of the `rating` scores. Your answer should be a new data frame with these three summary statistics in three columns. Label the name of these columns `mean`, `sd`, and `total`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n4.  Which country makes the best chocolate (or has the highest ratings on average) with beans from Ecuador?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n5.  Calculate the average rating across all country of origins for beans. Which top 3 countries have the highest ratings on average?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n6.  Following up on the previous problem, now remove any countries of bean origins that have less than 10 chocolate bar reviews. Now, which top 3 countries have the highest ratings on average?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n7.  For this last part, let's explore the relationship between percent chocolate and ratings.\n\nUse the functions in `dplyr`, `tidyr`, and `lubridate` to perform the following steps to the `chocolate` dataset:\n\n1.  Identify the countries of bean origin with at least 50 reviews. Remove reviews from countries are not in this list.\n2.  Using the variable describing the chocolate percentage for each review, create a new column that groups chocolate percentages into one of four groups: (i) \\<60%, (ii) \\>=60 to \\<70%, (iii) \\>=70 to \\<90%, and (iii) \\>=90% (**Hint** check out the `substr()` function in base R and the `case_when()` function from `dplyr` -- see example below).\n3.  Using the new column described in #2, re-order the factor levels (if needed) to be starting with the smallest percentage group and increasing to the largest percentage group (**Hint** check out the `fct_relevel()` function from `forcats`).\n4.  For each country, make a set of four side-by-side boxplots plotting the groups on the x-axis and the ratings on the y-axis. These plots should be faceted by country.\n\nOn average, which category of chocolate percentage is most highly rated? Do these countries mostly agree or are there disagreements?\n\n**Hint**: You may find the `case_when()` function useful in this part, which can be used to map values from one variable to different values in a new variable (when used in a `mutate()` call).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Generate some random numbers\ndat <- tibble(x = rnorm(100))\nslice(dat, 1:3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 1\n        x\n    <dbl>\n1 -1.17  \n2  0.0494\n3 -1.63  \n```\n:::\n\n```{.r .cell-code}\n## Create a new column that indicates whether the value of 'x' is positive or negative\ndat %>%\n        mutate(is_positive = case_when(\n                x >= 0 ~ \"Yes\",\n                x < 0 ~ \"No\"\n        ))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 2\n         x is_positive\n     <dbl> <chr>      \n 1 -1.17   No         \n 2  0.0494 Yes        \n 3 -1.63   No         \n 4 -1.43   No         \n 5 -0.934  No         \n 6  0.618  Yes        \n 7  0.877  Yes        \n 8 -0.568  No         \n 9 -0.459  No         \n10  1.75   Yes        \n# … with 90 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n# Part 2: Join two datasets together\n\nThe goal of this part of the assignment is to join two datasets together. `gapminder` is a [R package](https://cran.r-project.org/web/packages/gapminder/README.html) that contains an excerpt from the [Gapminder data](https://www.gapminder.org/data/).\n\n### Tasks\n\n1.  Use this dataset it to create a new column called `continent` in our `chocolate` dataset that contains the continent name for each review where the country of bean origin is.\n2.  Only keep reviews that have reviews from countries of bean origin with at least 10 reviews.\n3.  Also, remove the country of bean origin named `\"Blend\"`.\n4.  Make a set of violin plots with ratings on the y-axis and `continent`s on the x-axis.\n\n**Hint**:\n\n-   Check to see if there are any `NA`s in the new column. If there are any `NA`s, add the continent name for each row.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n# Part 3: Convert wide data into long data\n\nThe goal of this part of the assignment is to take a dataset that is either messy or simply not tidy and to make them tidy datasets. The objective is to gain some familiarity with the functions in the `dplyr`, `tidyr` packages. You may find it helpful to review the section on spreading and gathering data.\n\n### Tasks\n\nWe are going to create a set of features for us to plot over time. Use the functions in `dplyr` and `tidyr` to perform the following steps to the `chocolate` dataset:\n\n1.  Create a new set of columns titled `beans`, `sugar`, `cocoa_butter`, `vanilla`, `letchin`, and `salt` that contain a 1 or 0 representing whether or not that review for the chocolate bar contained that ingredient (1) or not (0).\n2.  Create a new set of columns titled `char_cocoa`, `char_sweet`, `char_nutty`, `char_creamy`, `char_roasty`, `char_earthy` that contain a 1 or 0 representing whether or not that the most memorable characteristic for the chocolate bar had that word (1) or not (0). For example, if the word \"sweet\" appears in the `most_memorable_characteristics`, then record a 1, otherwise a 0 for that review in the `char_sweet` column (**Hint**: check out `str_detect()` from the `stringr` package).\n3.  For each year (i.e. `review_date`), calculate the mean value in each new column you created across all reviews for that year. (**Hint**: If all has gone well thus far, you should have a dataset with 16 rows and 13 columns).\n4.  Convert this wide dataset into a long dataset with a new `feature` and `mean_score` column.\n\nIt should look something like this:\n\n    review_date     feature   mean_score\n    <dbl>           <chr>     <dbl>\n    2006    beans   1.000000000     \n    2006    sugar   1.000000000     \n    2006    cocoa_butter    0.925000000     \n    2006    vanilla 0.700000000     \n    2006    letchin 0.725000000     \n    2006    salt    0.000000000     \n    2006    char_cocoa  0.175000000     \n    2006    char_sweet  0.175000000     \n    2006    char_nutty  0.050000000     \n    2006    char_creamy 0.375000000 \n\n### Notes\n\n-   You may need to use functions outside these packages to obtain this result.\n\n-   Do not worry about the ordering of the rows or columns. Depending on whether you use `gather()` or `pivot_longer()`, the order of your output may differ from what is printed above. As long as the result is a tidy data set, that is sufficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n# Part 4: Data visualization\n\nIn this part of the project, we will continue to work with our now tidy song dataset from the previous part.\n\n### Tasks\n\nUse the functions in `ggplot2` package to make a scatter plot of the `mean_score`s (y-axis) over time (x-axis). One plot for each `mean_score`. For full credit, your plot should include:\n\n1.  An overall title for the plot and a subtitle summarizing key trends that you found. Also include a caption in the figure with your name.\n2.  Both the observed points for the `mean_score`, but also a smoothed non-linear pattern of the trend\n3.  All plots should be shown in the one figure\n4.  There should be an informative x-axis and y-axis label\n\nConsider playing around with the `theme()` function to make the figure shine, including playing with background colors, font, etc.\n\n### Notes\n\n-   You may need to use functions outside these packages to obtain this result.\n\n-   Don't worry about the ordering of the rows or columns. Depending on whether you use `gather()` or `pivot_longer()`, the order of your output may differ from what is printed above. As long as the result is a tidy data set, that is sufficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n# Part 5: Make the worst plot you can!\n\nThis sounds a bit crazy I know, but I want this to try and be FUN! Instead of trying to make a \"good\" plot, I want you to explore your creative side and make a really awful data visualization in every way. :)\n\n### Tasks\n\nUsing the `chocolate` dataset (or any of the modified versions you made throughout this assignment or anything else you wish you build upon it):\n\n1.  Make the absolute worst plot that you can. You need to customize it in **at least 7 ways** to make it awful.\n2.  In your document, write 1 - 2 sentences about each different customization you added (using bullets -- i.e. there should be at least 7 bullet points each with 1-2 sentences), and how it could be useful for you when you want to make an awesome data visualization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n\n\n# Part 6: Make my plot a better plot!\n\nThe goal is to take my sad looking plot and make it better! If you'd like an [example](https://twitter.com/drmowinckels/status/1392136510468763652), here is a tweet I came across of someone who gave a talk about how to zhoosh up your ggplots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchocolate %>%\n  ggplot(aes(x = as.factor(review_date), \n             y = rating, \n             fill = review_date)) +\n  geom_violin()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n### Tasks\n\n1.  You need to customize it in **at least 7 ways** to make it better.\n2.  In your document, write 1 - 2 sentences about each different customization you added (using bullets -- i.e. there should be at least 7 bullet points each with 1-2 sentences), describing how you improved it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add your solution here\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}