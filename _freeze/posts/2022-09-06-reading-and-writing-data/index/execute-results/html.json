{
  "hash": "ee2f47c31f854b5e990d4bff50e7da20",
  "result": {
    "markdown": "---\ntitle: \"Reading and Writing data\"\nauthor: \n  - name: Stephanie Hicks\n    url: https://stephaniehicks.com\n    affiliation: Department of Biostatistics, Johns Hopkins\n    affiliation_url: https://publichealth.jhu.edu\ndescription: \"How to get data in and out of R using relative paths\"\ndate: 2022-09-06\ncategories: [module 1, week 2, R, programming, readr, here, tidyverse]\n---\n\n::: {.cell}\n\n:::\n\n\n<!-- Add interesting quote -->\n\n> \"When writing code, you're always collaborating with future-you; and past-you doesn't respond to emails\". ---*Hadley Wickham*\n\n\\[[Source](https://fivebooks.com/best-books/computer-science-data-science-hadley-wickham/)\\]\n\n# Pre-lecture materials\n\n### Read ahead\n\n::: callout-note\n## Read ahead\n\n**Before class, you can prepare by reading the following materials:**\n\n1.  <https://rdpeng.github.io/Biostat776/lecture-getting-and-cleaning-data.html>\n2.  <https://jhudatascience.org/tidyversecourse/get-data.html>\n:::\n\n### Acknowledgements\n\nMaterial for this lecture was borrowed and adopted from\n\n-   <https://rdpeng.github.io/Biostat776/lecture-getting-and-cleaning-data.html>\n-   <https://r4ds.had.co.nz/data-import.html>\n\n# Learning objectives\n\n::: callout-note\n# Learning objectives\n\n**At the end of this lesson you will:**\n\n-   Know difference between relative vs absolute paths\n-   Be able to read and write text / csv files in R\n-   Be able to read and write R data objects in R\n-   Be able to calculate memory requirements for R objects\n-   Use modern R packages for reading and writing data\n:::\n\n# Introduction\n\nThis lesson introduces ways to read and write data (e.g. `.txt` and `.csv` files) using base R functions as well as more modern R packages, such as `readr`, which is typically [10x faster than base R](https://r4ds.had.co.nz/data-import.html#compared-to-base-r).\n\nWe will also briefly describe different ways for reading and writing other data types such as, Excel files, google spreadsheets, or SQL databases.\n\n# Relative versus absolute paths\n\nWhen you are starting a data analysis, you have already learned about the use of `.Rproj` files. When you open up a `.Rproj` file, RStudio changes the path (location on your computer) to the `.Rproj` location.\n\nAfter opening up a `.Rproj` file, you can test this by\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n:::\n\n\nWhen you open up someone else's R code or analysis, you might also see the\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd()\n```\n:::\n\n\nfunction being used which explicitly tells R to change the absolute path or absolute location of which directory to move into.\n\nFor example, say I want to clone a GitHub repo from Roger, which has 100 R script files, and in every one of those files at the top is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(\"C:\\Users\\Roger\\path\\only\\that\\Roger\\has\")\n```\n:::\n\n\nThe problem is, if I want to use his code, I will need to go and hand-edit every single one of those paths (`C:\\Users\\Roger\\path\\only\\that\\Roger\\has`) to the path that I want to use on my computer or wherever I saved the folder on my computer (e.g. `/Users/Stephanie/Documents/path/only/I/have`).\n\n1.  This is an unsustainable practice.\n2.  I can go in and manually edit the path, but this assumes I know how to set a working directory. Not everyone does.\n\nSo instead of absolute paths:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(\"/Users/jtleek/data\")\nsetwd(\"~/Desktop/files/data\")\nsetwd(\"C:\\\\Users\\\\Michelle\\\\Downloads\")\n```\n:::\n\n\nA better idea is to use relative paths:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetwd(\"../data\")\nsetwd(\"../files\")\nsetwd(\"..\\tmp\")\n```\n:::\n\n\nWithin R, an even better idea is to use the [here](https://github.com/r-lib/here) R package will recognize the top-level directory of a Git repo and supports building all paths relative to that. For more on project-oriented workflow suggestions, read [this post](https://www.tidyverse.org/articles/2017/12/workflow-vs-script/) from Jenny Bryan.\n\n![Artwork by Allison Horst on setwd() function](https://github.com/allisonhorst/stats-illustrations/raw/main/rstats-artwork/cracked_setwd.png){width=\"80%\"}\n\n\\[**Source**: [Artwork by Allison Horst](https://github.com/allisonhorst/stats-illustrations)\\]\n\n### The `here` package\n\nIn her post, Jenny Bryan writes\n\n> \"I suggest organizing each data analysis into a project: a folder on your computer that holds all the files relevant to that particular piece of work.\"\n\nInstead of using `setwd()` at the top your `.R` or `.Rmd` file, she suggests:\n\n-   Organize each logical project into a folder on your computer.\n-   Make sure the top-level folder advertises itself as such. This can be as simple as having an empty file named `.here`. Or, if you use RStudio and/or Git, those both leave characteristic files behind that will get the job done.\n-   Use the `here()` function from the `here` package to build the path when you read or write a file. Create paths relative to the top-level directory.\n-   Whenever you work on this project, launch the R process from the project's top-level directory. If you launch R from the shell, `cd` to the correct folder first.\n\nLet's test this out. We can use `getwd()` to see our current working directory path and the files available using `list.files()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/Users/stephaniehicks/Documents/github/teaching/jhustatcomputing2022/posts/2022-09-06-reading-and-writing-data\"\n```\n:::\n\n```{.r .cell-code}\nlist.files()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"index.qmd\"       \"index.rmarkdown\"\n```\n:::\n:::\n\n\nOK so our current location is in the reading and writing lectures sub-folder of the `jhustatcomputing2021` course repository. Let's try using the `here` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\n\nlist.files(here::here())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"_freeze\"                    \"_post_template.qmd\"        \n [3] \"_quarto.yml\"                \"_site\"                     \n [5] \"data\"                       \"images\"                    \n [7] \"index.qmd\"                  \"jhustatcomputing2022.Rproj\"\n [9] \"lectures.qmd\"               \"posts\"                     \n[11] \"profile.jpg\"                \"projects\"                  \n[13] \"projects.qmd\"               \"README.md\"                 \n[15] \"resources.qmd\"              \"schedule.qmd\"              \n[17] \"scripts\"                    \"styles.css\"                \n[19] \"syllabus.qmd\"               \"videos\"                    \n```\n:::\n\n```{.r .cell-code}\nlist.files(here(\"data\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2016-07-19.csv.bz2\" \"chicago.rds\"        \"chocolate.RDS\"     \n[4] \"team_standings.csv\"\n```\n:::\n:::\n\n\nNow we see that using the `here::here()` function is a *relative* path (relative to the `.Rproj` file in our `jhustatcomputing2021` repository. We also see there is are two `.csv` files in the `data` folder. We will learn how to read those files into R in the next section.\n\n![Artwork by Allison Horst on here package](https://github.com/allisonhorst/stats-illustrations/raw/main/rstats-artwork/here.png){width=\"80%\"}\n\n\\[**Source**: [Artwork by Allison Horst](https://github.com/allisonhorst/stats-illustrations)\\]\n\n### Finding and creating files locally\n\nOne last thing. If you want to download a file, one way to use the `file.exists()`, `dir.create()` and `list.files()` functions.\n\n-   `file.exists(here(\"my\", \"relative\", \"path\"))`: logical test if the file exists\n-   `dir.create(here(\"my\", \"relative\", \"path\"))`: create a folder\n-   `list.files(here(\"my\", \"relative\", \"path\"))`: list contents of folder\n-   `file.create(here(\"my\", \"relative\", \"path\"))`: create a file\n-   `file.remove(here(\"my\", \"relative\", \"path\"))`: delete a file\n\nFor example, I can put all this together by\n\n1.  Checking to see if a file exists in my path. If not, then\n2.  Create a directory in that path.\n3.  List the files in the path.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(!file.exists(here(\"my\", \"relative\", \"path\"))){\n  dir.create(here(\"my\", \"relative\", \"path\"))\n}\nlist.files(here(\"my\", \"relative\", \"path\"))\n```\n:::\n\n\nLet's put relative paths to use while reading and writing data.\n\n# Reading data in base R\n\nIn this section, we're going to demonstrate the essential functions you need to know to read and write (or save) data in R.\n\n### txt or csv\n\nThere are a few primary functions reading data from base R.\n\n-   `read.table()`, `read.csv()`: for reading tabular data\n-   `readLines()`: for reading lines of a text file\n\nThere are analogous functions for writing data to files\n\n-   `write.table()`: for writing tabular data to text files (i.e. CSV) or connections\n-   `writeLines()`: for writing character data line-by-line to a file or connection\n\nLet's try reading some data into R with the `read.csv()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- read.csv(here(\"data\", \"team_standings.csv\"))\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Standing         Team\n1         1        Spain\n2         2  Netherlands\n3         3      Germany\n4         4      Uruguay\n5         5    Argentina\n6         6       Brazil\n7         7        Ghana\n8         8     Paraguay\n9         9        Japan\n10       10        Chile\n11       11     Portugal\n12       12          USA\n13       13      England\n14       14       Mexico\n15       15  South Korea\n16       16     Slovakia\n17       17  Ivory Coast\n18       18     Slovenia\n19       19  Switzerland\n20       20 South Africa\n21       21    Australia\n22       22  New Zealand\n23       23       Serbia\n24       24      Denmark\n25       25       Greece\n26       26        Italy\n27       27      Nigeria\n28       28      Algeria\n29       29       France\n30       30     Honduras\n31       31     Cameroon\n32       32  North Korea\n```\n:::\n:::\n\n\nWe can use the `$` symbol to pick out a specific column:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$Team\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Spain\"        \"Netherlands\"  \"Germany\"      \"Uruguay\"      \"Argentina\"   \n [6] \"Brazil\"       \"Ghana\"        \"Paraguay\"     \"Japan\"        \"Chile\"       \n[11] \"Portugal\"     \"USA\"          \"England\"      \"Mexico\"       \"South Korea\" \n[16] \"Slovakia\"     \"Ivory Coast\"  \"Slovenia\"     \"Switzerland\"  \"South Africa\"\n[21] \"Australia\"    \"New Zealand\"  \"Serbia\"       \"Denmark\"      \"Greece\"      \n[26] \"Italy\"        \"Nigeria\"      \"Algeria\"      \"France\"       \"Honduras\"    \n[31] \"Cameroon\"     \"North Korea\" \n```\n:::\n:::\n\n\nWe can also ask for the full paths for specific files\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere(\"data\", \"team_standings.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/Users/stephaniehicks/Documents/github/teaching/jhustatcomputing2022/data/team_standings.csv\"\n```\n:::\n:::\n\n\n::: questions\n**Questions**:\n\n-   What happens when you use `readLines()` function with the `team_standings.csv` data?\n-   How would you only read in the first 5 lines?\n:::\n\n### R code\n\nSometimes, someone will give you a file that ends in a `.R`. This is what's called an R script file. It may contain code someone has written (maybe even you!), for example, a function that you can use with your data. In this case, you want the function available for you to use. To use the function, you have to first, read in the function from R script file into R.\n\nYou can check to see if the function already is loaded in R by looking at the Environment tab.\n\nThe function you want to use is\n\n-   `source()`: for reading in R code files\n\nFor example, it might be something like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(here::here('functions.R'))\n```\n:::\n\n\n### R objects\n\nAlternatively, you might be interested in reading and writing R objects.\n\nWriting data in e.g. `.txt`, `.csv` or Excel file formats is good if you want to open these files with other analysis software, such as Excel. However, these formats do not preserve data structures, such as column data types (numeric, character or factor). In order to do that, the data should be written out in a R data format.\n\nThere are several types R data file formats to be aware of:\n\n-   `.RData`: Stores **multiple** R objects\n-   `.Rda`: This is short for `.RData` and is equivalent.\n-   `.Rds`: Stores a **single** R object\n\n::: questions\n**Question: why is saving data in as a R object useful?**\n\nSaving data into R data formats can **typically** reduce considerably the size of large files by compression.\n:::\n\nNext, we will learn how to save\n\n1.  A single R object\n2.  Multiple R objects\n3.  Your entire work space in a specified file\n\n**Reading in data from files**\n\n-   `load()`: for reading in single or multiple R objects (opposite of `save()`) with a `.Rda` or `.RData` file format (objects must be same name)\n-   `readRDS()`: for reading in a single object with a `.Rds` file format (can rename objects)\n-   `unserialize()`: for reading single R objects in binary form\n\n**Writing data to files**\n\n-   `save()`: for saving an arbitrary number of R objects in binary format (possibly compressed) to a file.\n-   `saveRDS()`: for saving a single object\n-   `serialize()`: for converting an R object into a binary format for outputting to a connection (or file).\n-   `save.image()`: short for 'save my current workspace; while this *sounds* nice, it's not terribly useful for reproducibility (hence not suggested); it's also what happens when you try to quit R and it asks if you want to save your work space.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Save data into R data file formats: RDS and RDATA](http://www.sthda.com/sthda/RDoc/images/save-data-into-r-data-formats.png)\n:::\n:::\n\n\n\\[[Source](http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata)\\]\n\nLet's try an example. Let's save a vector of length 5 into the two file formats.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:5\nsave(x, file=here(\"data\", \"x.Rda\"))\nsaveRDS(x, file=here(\"data\", \"x.Rds\"))\nlist.files(path=here(\"data\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2016-07-19.csv.bz2\" \"chicago.rds\"        \"chocolate.RDS\"     \n[4] \"team_standings.csv\" \"x.Rda\"              \"x.Rds\"             \n```\n:::\n:::\n\n\nHere we assign the imported data to an object using `readRDS()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_x1 <- readRDS(here(\"data\", \"x.Rds\"))\nnew_x1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3 4 5\n```\n:::\n:::\n\n\nHere we assign the imported data to an object using `load()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_x2 <- load(here(\"data\", \"x.Rda\"))\nnew_x2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"x\"\n```\n:::\n:::\n\n\n**NOTE: `load()` simply returns the name of the objects loaded. Not the values.**\n\nLet's clean up our space.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.remove(here(\"data\", \"x.Rda\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nfile.remove(here(\"data\", \"x.Rds\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nrm(x)\n```\n:::\n\n\n::: questions\nWhat do you think this code will do?\n\n**Hint**: change `eval=TRUE` to see result\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:5\ny <- x^2\nsave(x,y, file=here(\"data\", \"x.Rda\"))\nnew_x2 <- load(here(\"data\", \"x.Rda\"))\n```\n:::\n\n\nWhen you are done:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.remove(here(\"data\", \"x.Rda\"))\n```\n:::\n\n:::\n\nNow, there are of course, many R packages that have been developed to read in all kinds of other datasets, and you may need to resort to one of these packages if you are working in a specific area.\n\nFor example, check out\n\n-   [`DBI`](https://github.com/r-dbi/DBI) for relational databases\n-   [`haven`](https://haven.tidyverse.org) for SPSS, Stata, and SAS data\n-   [`httr`](https://github.com/r-lib/httr) for web APIs\n-   [`readxl`](https://readxl.tidyverse.org) for `.xls` and `.xlsx` sheets\n-   [`googlesheets4`](https://googlesheets4.tidyverse.org) for Google Sheets\n-   [`googledrive`](https://googledrive.tidyverse.org) for Google Drive files\n-   [`rvest`](https://github.com/tidyverse/rvest) for web scraping\n-   [`jsonlite`](https://github.com/jeroen/jsonlite#jsonlite) for JSON\n-   [`xml2`](https://github.com/r-lib/xml2) for XML.\n\n# Reading data files with `read.table()`\n\nThe `read.table()` function is one of the most commonly used functions for reading data. The help file for `read.table()` is worth reading in its entirety if only because the function gets used a lot (run `?read.table` in R). I know, I know, everyone always says to read the help file, but this one is actually worth reading.\n\nThe `read.table()` function has a few important arguments:\n\n-   `file`, the name of a file, or a connection\n-   `header`, logical indicating if the file has a header line\n-   `sep`, a string indicating how the columns are separated\n-   `colClasses`, a character vector indicating the class of each column in the dataset\n-   `nrows`, the number of rows in the dataset. By default `read.table()` reads an entire file.\n-   `comment.char`, a character string indicating the comment character. This defalts to `\"#\"`. If there are no commented lines in your file, it's worth setting this to be the empty string `\"\"`.\n-   `skip`, the number of lines to skip from the beginning\n-   `stringsAsFactors`, should character variables be coded as factors? This defaults to `FALSE`. However, back in the \"old days\", it defaulted to `TRUE`. The reason for this was because, if you had data that were stored as strings, it was because those strings represented levels of a categorical variable. Now, we have lots of data that is text data and they do not always represent categorical variables. So you may want to set this to be `FALSE` in those cases. If you *always* want this to be `FALSE`, you can set a global option via `options(stringsAsFactors = FALSE)`. I've never seen so much heat generated on discussion forums about an R function argument than the `stringsAsFactors` argument. Seriously.\n\nFor small to moderately sized datasets, you can usually call `read.table()` without specifying any other arguments\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.table(\"foo.txt\")\n```\n:::\n\n\n**Note**: `foo.txt` is not a real dataset here. It is only used as an example for how to use `read.table()`.\n\nIn this case, R will automatically:\n\n-   skip lines that begin with a \\#\n-   figure out how many rows there are (and how much memory needs to be allocated)\n-   figure what type of variable is in each column of the table.\n\nTelling R all these things directly makes R run faster and more efficiently. The `read.csv()` function is identical to `read.table()` except that some of the defaults are set differently (like the `sep` argument).\n\n# Reading in larger datasets with `read.table()`\n\nWith much larger datasets, there are a few things that you can do that will make your life easier and will prevent R from choking.\n\n-   Read the help page for `read.table()`, which contains many hints\n-   Make a rough calculation of the memory required to store your dataset (see the next section for an example of how to do this). If the dataset is larger than the amount of RAM on your computer, you can probably stop right here.\n-   Set `comment.char = \"\"` if there are no commented lines in your file.\n-   Use the `colClasses` argument. Specifying this option instead of using the default can make `read.table()` run MUCH faster, often twice as fast. In order to use this option, you have to know the class of each column in your data frame. If all of the columns are \"numeric\", for example, then you can just set `colClasses = \"numeric\"`. A quick an dirty way to figure out the classes of each column is the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninitial <- read.table(\"datatable.txt\", nrows = 100)\nclasses <- sapply(initial, class)\ntabAll <- read.table(\"datatable.txt\", colClasses = classes)\n```\n:::\n\n\n**Note**: `datatable.txt` is not a real dataset here. It is only used as an example for how to use `read.table()`.\n\n-   Set `nrows`. This does not make R run faster but it helps with memory usage. A mild overestimate is okay. You can use the Unix tool `wc` to calculate the number of lines in a file.\n\nIn general, when using R with larger datasets, it's also useful to know a few things about your system.\n\n-   How much memory is available on your system?\n-   What other applications are in use? Can you close any of them?\n-   Are there other users logged into the same system?\n-   What operating system ar you using? Some operating systems can limit the amount of memory a single process can access\n\n# Calculating Memory Requirements for R Objects\n\nBecause R stores all of its objects physical memory, it is important to be cognizant of how much memory is being used up by all of the data objects residing in your workspace. One situation where it is particularly important to understand memory requirements is when you are reading in a new dataset into R. Fortunately, it is easy to make a back of the envelope calculation of how much memory will be required by a new dataset.\n\nFor example, suppose I have a data frame with 1,500,000 rows and 120 columns, all of which are numeric data. Roughly, how much memory is required to store this data frame?\n\nWell, on most modern computers [double precision floating point numbers](http://en.wikipedia.org/wiki/Double-precision_floating-point_format) are stored using 64 bits of memory, or 8 bytes. Given that information, you can do the following calculation\n\n1,500,000 × 120 × 8 bytes/numeric = 1,440,000,000 bytes\n\n= 1,440,000,000 / 2^20^ bytes/MB\n\n= 1,373.29 MB\n\n= 1.34 GB\n\nSo the dataset would require about 1.34 GB of RAM. Most computers these days have at least that much RAM. However, you need to be aware of\n\n-   what other programs might be running on your computer, using up RAM\n-   what other R objects might already be taking up RAM in your workspace\n\nReading in a large dataset for which you do not have enough RAM is one easy way to freeze up your computer (or at least your R session). This is usually an unpleasant experience that usually requires you to kill the R process, in the best case scenario, or reboot your computer, in the worst case. So make sure to do a rough calculation of memory requirements before reading in a large dataset. You'll thank me later.\n\n# Using the `readr` package\n\nThe `readr` package is recently developed by RStudio to deal with reading in large flat files quickly. The package provides replacements for functions like `read.table()` and `read.csv()`. The analogous functions in `readr` are `read_table()` and `read_csv()`. These functions are often *much* faster than their base R analogues and provide a few other nice features such as progress meters.\n\nFor example, the package includes a variety of functions in the `read_*` family that allow you to read in data from different formats of flat files. The following table gives a guide to several functions in the `read_*` family.\n\n\n::: {.cell}\n::: {.cell-output-display}\n|`readr` function |Use                                          |\n|:----------------|:--------------------------------------------|\n|`read_csv`       |Reads comma-separated file                   |\n|`read_csv2`      |Reads semicolon-separated file               |\n|`read_tsv`       |Reads tab-separated file                     |\n|`read_delim`     |General function for reading delimited files |\n|`read_fwf`       |Reads fixed width files                      |\n|`read_log`       |Reads log files                              |\n:::\n:::\n\n\n**Note**: In this code, I have used the `kable()` function from the `knitr` package to create the summary table in a table format, rather than as basic R output. This function is very useful for formatting basic tables in R markdown documents. For more complex tables, check out the `pander` and `xtable` packages.\n\nFor the most part, you can read use `read_table()` and `read_csv()` pretty much anywhere you might use `read.table()` and `read.csv()`. In addition, if there are non-fatal problems that occur while reading in the data, you will get a warning and the returned data frame will have some information about which rows/observations triggered the warning. This can be very helpful for \"debugging\" problems with your data before you get neck deep in data analysis.\n\nThe importance of the `read_csv()` function is perhaps better understood from an historical perspective. R's built in `read.csv()` function similarly reads CSV files, but the `read_csv()` function in `readr` builds on that by removing some of the quirks and \"gotchas\" of `read.csv()` as well as dramatically optimizing the speed with which it can read data into R. The `read_csv()` function also adds some nice user-oriented features like a progress meter and a compact method for specifying column types.\n\nA typical call to `read_csv()` will look as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nteams <- read_csv(here(\"data\", \"team_standings.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 32 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Team\ndbl (1): Standing\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nteams\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 32 × 2\n   Standing Team       \n      <dbl> <chr>      \n 1        1 Spain      \n 2        2 Netherlands\n 3        3 Germany    \n 4        4 Uruguay    \n 5        5 Argentina  \n 6        6 Brazil     \n 7        7 Ghana      \n 8        8 Paraguay   \n 9        9 Japan      \n10       10 Chile      \n# … with 22 more rows\n```\n:::\n:::\n\n\nBy default, `read_csv()` will open a CSV file and read it in line-by-line. Similar to `read.table()`, you can tell the function to `skip` lines or which lines are comments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_csv(\"The first line of metadata\n  The second line of metadata\n  x,y,z\n  1,2,3\",\n  skip = 2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n      x     y     z\n  <dbl> <dbl> <dbl>\n1     1     2     3\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nread_csv(\"# A comment I want to skip\n  x,y,z\n  1,2,3\",\n  comment = \"#\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n      x     y     z\n  <dbl> <dbl> <dbl>\n1     1     2     3\n```\n:::\n:::\n\n\nIt will also (by default), read in the first few rows of the table in order to figure out the type of each column (i.e. integer, character, etc.). From the `read_csv()` help page:\n\n> If 'NULL', all column types will be imputed from the first 1000 rows on the input. This is convenient (and fast), but not robust. If the imputation fails, you'll need to supply the correct types yourself.\n\nYou can specify the type of each column with the `col_types` argument.\n\nIn general, it is a good idea to specify the column types explicitly. This rules out any possible guessing errors on the part of `read_csv()`. Also, specifying the column types explicitly provides a useful safety check in case anything about the dataset should change without you knowing about it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nteams <- read_csv(here(\"data\", \"team_standings.csv\"), \n                  col_types = \"cc\")\n```\n:::\n\n\nNote that the `col_types` argument accepts a compact representation. Here `\"cc\"` indicates that the first column is `character` and the second column is `character` (there are only two columns). Using the `col_types` argument is useful because often it is not easy to automatically figure out the type of a column by looking at a few rows (especially if a column has many missing values).\n\nThe `read_csv()` function will also read compressed files automatically. There is no need to decompress the file first or use the `gzfile` connection function. The following call reads a gzip-compressed CSV file containing download logs from the RStudio CRAN mirror.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogs <- read_csv(here(\"data\", \"2016-07-19.csv.bz2\"), \n                 n_max = 10)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 10 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (6): r_version, r_arch, r_os, package, version, country\ndbl  (2): size, ip_id\ndate (1): date\ntime (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nNote that the warnings indicate that `read_csv()` may have had some difficulty identifying the type of each column. This can be solved by using the `col_types` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogs <- read_csv(here(\"data\", \"2016-07-19.csv.bz2\"), \n                 col_types = \"ccicccccci\", \n                 n_max = 10)\nlogs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 10\n   date       time       size r_ver…¹ r_arch r_os  package version country ip_id\n   <chr>      <chr>     <int> <chr>   <chr>  <chr> <chr>   <chr>   <chr>   <int>\n 1 2016-07-19 22:00:00 1.89e6 3.3.0   x86_64 ming… data.t… 1.9.6   US          1\n 2 2016-07-19 22:00:05 4.54e4 3.3.1   x86_64 ming… assert… 0.1     US          2\n 3 2016-07-19 22:00:03 1.43e7 3.3.1   x86_64 ming… stringi 1.1.1   DE          3\n 4 2016-07-19 22:00:05 1.89e6 3.3.1   x86_64 ming… data.t… 1.9.6   US          4\n 5 2016-07-19 22:00:06 3.90e5 3.3.1   x86_64 ming… foreach 1.4.3   US          4\n 6 2016-07-19 22:00:08 4.88e4 3.3.1   x86_64 linu… tree    1.0-37  CO          5\n 7 2016-07-19 22:00:12 5.25e2 3.3.1   x86_64 darw… surviv… 2.39-5  US          6\n 8 2016-07-19 22:00:08 3.23e6 3.3.1   x86_64 ming… Rcpp    0.12.5  US          2\n 9 2016-07-19 22:00:09 5.56e5 3.3.1   x86_64 ming… tibble  1.1     US          2\n10 2016-07-19 22:00:10 1.52e5 3.3.1   x86_64 ming… magrit… 1.5     US          2\n# … with abbreviated variable name ¹​r_version\n```\n:::\n:::\n\n\nYou can specify the column type in a more detailed fashion by using the various `col_*` functions. For example, in the log data above, the first column is actually a date, so it might make more sense to read it in as a `Date` object. If we wanted to just read in that first column, we could do\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogdates <- read_csv(here(\"data\", \"2016-07-19.csv.bz2\"), \n                     col_types = cols_only(date = col_date()),\n                     n_max = 10)\nlogdates\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 1\n   date      \n   <date>    \n 1 2016-07-19\n 2 2016-07-19\n 3 2016-07-19\n 4 2016-07-19\n 5 2016-07-19\n 6 2016-07-19\n 7 2016-07-19\n 8 2016-07-19\n 9 2016-07-19\n10 2016-07-19\n```\n:::\n:::\n\n\nNow the `date` column is stored as a `Date` object which can be used for relevant date-related computations (for example, see the `lubridate` package).\n\n**Note**: The `read_csv()` function has a `progress` option that defaults to TRUE. This options provides a nice progress meter while the CSV file is being read. However, if you are using `read_csv()` in a function, or perhaps embedding it in a loop, it is probably best to set `progress = FALSE`.\n\n# Post-lecture materials\n\n### Final Questions\n\nHere are some post-lecture questions to help you think about the material discussed.\n\n::: callout-note\n### Questions\n\n1.  What is the point of reference for using relative paths with the `here::here()` function?\n\n2.  Why was the argument `stringsAsFactors=TRUE` historically used?\n\n3.  What is the difference between `.Rds` and `.Rda` file formats?\n\n4.  What function in `readr` would you use to read a file where fields were separated with \"\\|\"?\n:::\n\n### Additional Resources\n\n::: callout-tip\n-   <https://swcarpentry.github.io/r-novice-inflammation/11-supp-read-write-csv>\n-   <https://support.rstudio.com/hc/en-us/articles/218611977-Importing-Data-with-the-RStudio-IDE>\n-   <https://jhudatascience.org/tidyversecourse/get-data.html>\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}